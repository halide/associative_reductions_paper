\subsection{Reduction in Halide}

List some associative reduction operations: histogram, sum over reduction dimension, etc. Old way to parallelize / vectorize such operations: user need to manually define intermediate functions that do reduction over partial domain and combine the partial results. Pretty tedious and error prone to do manually, especially when the domain is not rectangular (user can specify predicate on the reduction domain via the 'where' directives) -> have to make sure the intermediate functions have the correct new reduction domain, etc. Other issue: some equations are not obviously associative, e.g. \code{x + y + k*x*y} where \code{k} is a constant. \\

Proposed solution: new scheduling directive \code{rfactor}. Calling \code{rfactor} on a Halide associative update definition splits the update into an intermediate which computes the partial results and a new update definition which merges the partial results. \code{rfactor} makes a best-effort attempt to automatically infer the associative reduction operator and identity of the operator.

\subsection{\code{rfactor} DAG Transformation}

Throughout this section, assume that the associative operator and its identity are known. \\

We present a Halide scheduling primitive (DAG transformation), \code{rfactor}, that creates a new data parallel axis out of a reduction. <Insert brief explanation on \code{rfactor} syntax>. \code{rfactor} removes specified reduction dimensions from the final (or better referred as the *merge* function generated by \code{rfactor}) and lifts them to the intermediate function. The remaining reduction dimensions are made *pure* in the intermediate function, which allows them to be vectorized or parallelized. <TODO: Maybe there is a less confusing way to explain this?>

<Insert DAG transformation using \code{rfactor} on some synthetic example> \\

<Insert figures of code with and without using \code{rfactor}: histogram, matrix multiply, other associative ops with non-rectangular domain> \\

<TODO: Matrix multiply> \\

\begin{lstlisting}[caption={Histogram: serial version, hand-rollled parallel associative reduction version, and rfactor parallel associative reduction version}]
// Serial version
Func hist;
Var x("x");
hist(x) = 0;
RDom r(input.width(), input.height());
hist(clamp(cast<int>(input(r.x, r.y)), 0, 255)) =
  hist(clamp(cast<int>(input(r.x, r.y)), 0, 255)) 
  + 1;

// Hand-rolled version: compute histogram along 
// the x-scanline for each y in parallel, then 
// reduce the partial results
Func intm;
Var u("u");
intm(u) = 0;
RDom rx(input.width());
intm(clamp(cast<int>(input(rx, u)), 0, 255)) = 
  intm(clamp(cast<int>(input(rx, u)), 0, 255)) 
  + 1;
intm.compute_root();
intm.update(0).parallel(u);

Func hist;
Var x("x");
hist(x) = 0;
RDom ry(input.height());
hist(clamp(cast<int>(intm(ry)), 0, 255)) =
  hist(clamp(cast<int>(intm(ry)), 0, 255)) 
  + 1;

// rfactor version : compute histogram along  
// the x-scanline for each y in parallel, then  
// reduce the partial results
Func hist;
Var x("x");
hist(x) = 0;
RDom r(in.width(), in.height());
hist(clamp(cast<int>(in(r.x, r.y)), 0, 255)) =
  hist(clamp(cast<int>(in(r.x, r.y)), 0, 255)) 
  + 1;

Var u("u");
Func intm = hist.update(0).rfactor(r.y, u);
intm.compute_root();
intm.update(0).parallel(u);
\end{lstlisting}

\begin{lstlisting}[caption={2D summation over a circular reduction domain with radius of 10: serial version, hand-rollled parallel associative reduction version, and rfactor parallel associative reduction version}]
// Serial version
Func sum;
sum() = 0;
RDom r(in.width(), in.height());
r.where(r.x*r.x + r.y*r.y <= 100);
sum() = sum() + in(r.x, r.y);

// Hand-rolled version: compute the sum along 
// the x-scanline for each y in parallel, then 
// reduce the partial results
Func intm;
Var u("u");
intm(u) = 0;
RDom rx(in.width());
rx.where(rx*rx + u*u <= 100);
intm(u) = intm(u) + in(rx, u);
intm.compute_root();
intm.update(0).parallel(u);

Func sum;
Var x("x");
sum() = 0;
RDom ry(in.height());
sum() = sum() + intm(ry);

// rfactor version : compute the sum along 
// the x-scanline for each y in parallel, then 
// reduce the partial results
Func sum;
Var x("x");
sum() = 0;
RDom r(in.width(), in.height());
r.where(r.x*r.x + r.y*r.y <= 100);
sum() = sum() + in(r.x, r.y);

Var u("u");
Func intm = sum.update(0).rfactor(r.y, u);
intm.compute_root();
intm.update(0).parallel(u);
\end{lstlisting}


Make sure to state the restriction of \textsc{rfactor}: the intermediate and merge functions have to be of the same form. For example: if the intermediate function is \code{min(x, y)}, the merge function has to be \code{min(x, y)}. \textsc{rfactor} also only handles binary associative operators: something of the form \code{op(x, y)}. \code{op(y)} is okay, although it is no longer a 'reduction' operator. The associative ops also have to have identity. Consequences: restricted form of more general map/reduce -> we can't split the works in \code{f() = f() -  g(r.x)} for example. Theoretically this is possible, provided we use "-" for the intermediate with identity of 0 and "+" for the merge, but this is not supported by \textsc{rfactor} <Insert code snippet for the subtraction case> \\

<TODO: Find better terms for the intermediate and merge functions returned by \textsc{rfactor}> \\

\subsection{Deducing Associative Operator}

\subsubsection{Forward Synthesis}

We took the forward synthesis approach to deduce the associative operator from an update definition: perform a wild-card matching over a list of pre-generated associative op patterns. We synthesize a bunch of math expressions (using min/max/add/sub/etc) for 1-element, 2-element tuple, etc., and use Z3 theorem prover \cite{DeMoura:2008:ZES:1792734.1792766} to prove the associativity of the math expression and compute its identity. \\

<Insert some baby example + code snippet on how we come up with the right associative op given some Halide udpate definition> \\

Why not backward synthesis (try to "sketch" the intermediate and merge functions)? We tried MIT Sketch and Rosette, but it is too slow to be practical for runtime deduction: Sketch didn't terminate for complex multiplication, Rosette finished in about 1 hour for a very restricted form of the complex multiplication synthesis problem (restrict x to be in LHS only -> can't have y*x, and we also *tell* Rosette that the answer is probably of the form \code{op(op(x??, y??), op(x??, y??)))}. Instead, we use synthesis to pre-generate list of binary associative ops, that we can use to infer the correct associative forms when calling rfactor on an update definition. \\

\subsubsection{Subgraph Decomposition}

Given a tuple of update definition, reduce the problem before the search by reasoning on the graph of dependencies between tuple elements. Construct a directed graph of dependencies between tuple elements, and decompose it into subgraphs. Each tuple element is assigned as a vertex in the graph. For tuple with arity $N$, there will be $N$ vertices. Example: list of vertices of update definition \code{f() = \{f()[0] + g(r.x), f()[1]*h(r.x)\} is \{f()[0], f()[1]\}}. \\

<TODO: Find a better term for 'subgraph'. Maybe there is already one?> \\

Definition of subgraph of $S_V$: set of all vertices that are reachable from a given vertex $V$. A graph of $N$ vertices will have $N$ subgraphs which members may overlap. Examples: 
\begin{enumerate}
 \item Computing reduction of complex-number addition over g: \code{f() = \{f()[0] + g(r.x)[0], f()[1] + g(r.x)[1]\}} -> list of subgraphs: \code{f()[0] : \{f()[0]\}, f()[1] : \{f()[1]\}} <Insert figure of the graph/subgraphs>
 \item Computing reduction ofo complex-number multiplication over g: \code{f() = \{f()[0]*g(r.x)[0] - f()[1]*g(r.x)[1], f()[1]*g(r.x)[0] + f()[0]*g(r.x)[1]\}} -> list of subgraphs: \code{f()[0] : \{f()[0], f()[1]\}, f()[1] : \{f()[0], f()[1]\}} <Insert figure of the graph/subgraphs>
 \item Computing 2D argmin of g: \code{f() = \{min(f()[0], g(r.x, r.y)), select(f()[0] < g(r.x, r.y), f()[1], r.x), select(f()[0] < g(r.x), f()[1], r.y)\}} -> list of subgraphs: \code{f()[0] : \{f(x)[0]\}, f()[1] : \{f(x)[0], f(x)[1]\}, f()[2] : \{f(x)[0], f(x)[2]\}} <Insert figure of the graph/subgraphs>
\end{enumerate}

Reduce the associative op deduction problem via subgraph decomposition. Overlaps are okay. If a subgraph is fully contained in (subset of) another subgraph, no need to consider it during the deduction. For the 2D argmin examples above, there are 2 relevant subgraphs (the ones originated from \code{f()[1]} and \code{f()[2]}). Subgraph of \code{f()[0]} is subset of either \code{f()[1]} or \code{f()[2]} -> we can ignore \code{f()[0]} from consideration. The problem boils down to deducing associative ops and its identity for 1D argmin. Merging the results: if an element $x_i$ is in both subgraph $V_p$ and $V_q$, need to ensure that binary operators (plus identities) deduced from $V_p$ and $V_q$ are consistent. If there is contradiction, bails out. <TODO: Is it necessarily true that if there is contradiction, the tuple is not associative? If not, find an example.> \\

\paragraph{Proof}
<TODO: Derive formal proof. Why is it okay to decompose the problem into subgraphs and perform the deduction separately?> \\


