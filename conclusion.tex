In this paper, we have presented a new Halide scheduling primitive called \code{rfactor}, which moves reduction factorization into the \emph{schedule}, while maintaining Halide's consistency guarantees. We have also introduced a novel synthesis-based technique that takes serial Halide reductions and synthesizes an equivalent binary associative reduction operator and its identity. These enable us to automatically decompose a reduction pipeline stage into a pair of stages: \emph{intermediate} stage that first computes partial results over slices of the reduction domain, and \emph{merge} stage that combines them. This, in turn, allows parallelization and vectorization of Halide algorithms which previously required manipulating both the algorithm and schedule. In addition to moving the burden of factoring a reduction from the programmer, \code{rfactor} also improves code readability and portability and further separates the \emph{algorithm} from its \emph{schedule} which enables automatic schedule generation tools to parallelize reductions. 

Although our framework is able to handle a broad range of reductions, there are several limitations. First, we constrain \code{rfactor} to handle only reductions where the \emph{intermediate} and \emph{merge} stages have the same equivalent binary associative reduction operator. The binary associative operator must also have an identity that is used to initialize the \emph{intermediate} stage. As a consequence, we are unable to handle some reduction operator such as \code{f() = f() -  g(r.x)} which in theory is parallelizable provided we use ``$-$'' for the \emph{intermediate} stage and ``$+$'' for the \emph{merge} stage. The types of expressions we can handle are also constrained by the pre-computed look-up table: we can only deduce associativity of reduction patterns exist in the table, i.e. any expression that is covered in our search and is provable to be associative by Z3 during the look-up table generation. 

<TODO: Future work, etc>


